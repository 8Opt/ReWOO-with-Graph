llm: 
  provider: groq
  settings: 
    model:  llama3-70b-8192
    temperature: 1.
    max_tokens: 128

tools: 
  search:
    provider: tavily            # Details at: https://docs.tavily.com/docs/tavily-api/python-sdk
    settings: 
      max_results: 5
      search_depth: 'basic'     # ['basic', 'advances']

eval:
  provider: gemini
  settings: 
    model: gemini-1.5-flash
    temperature: 0
    max_tokens: 16